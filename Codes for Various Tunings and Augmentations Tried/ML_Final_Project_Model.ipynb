{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acbe7644-7f0e-45f0-afb9-0b7629a24043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bb94bf-5846-45e4-9a37-4cffe611b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"ml-files-img\"  # Replace with your bucket name\n",
    "bucket = storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6bf07b8-5acb-42d7-a985-9f6770e169db",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = bucket.list_blobs()\n",
    "#for blob in blobs:\n",
    "#    print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db00786-3609-443f-8d62-8f33b7ff0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r /home/jupyter/images\n",
    "#!rm -r /home/jupyter/proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cc98e7c-9ee0-4f43-8880-875f526c2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_directory = \"proj\"  # Replace with your desired local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b80904-0f66-4480-a217-2956b2bf2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#\n",
    "#import os\n",
    "#\n",
    "#os.makedirs(local_directory, exist_ok=True)\n",
    "#\n",
    "## List all the objects in the bucket\n",
    "#blobs = bucket.list_blobs()\n",
    "#\n",
    "## Iterate over the objects and download the images\n",
    "#for blob in blobs:\n",
    "#    if blob.name.endswith(\".bmp\") or blob.name.endswith(\".jpg\") or blob.name.endswith(\".png\"):\n",
    "#        # Construct the local file path\n",
    "#        local_file_path = os.path.join(local_directory, os.path.basename(blob.name))\n",
    "#        # Download the image file\n",
    "#        blob.download_to_filename(local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a28ac08f-b4a4-4bf9-b817-c87ade9b042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#\n",
    "#import os\n",
    "#\n",
    "#os.makedirs(local_directory, exist_ok=True)\n",
    "#\n",
    "## List all the objects in the bucket\n",
    "#blobs = bucket.list_blobs()\n",
    "#\n",
    "## Iterate over the objects and download the images\n",
    "#for blob in blobs:\n",
    "#    if blob.name.endswith(\".csv\"):\n",
    "#        # Construct the local file path\n",
    "#        local_file_path = os.path.join(local_directory, os.path.basename(blob.name))\n",
    "#        # Download the image file\n",
    "#        blob.download_to_filename(local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6479388-0806-4985-b2f5-71aaf4636cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c3b700c-785e-45e0-a61a-e84714510f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ed3c826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 18:16:36.100473: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 18:16:38.878129: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-20 18:16:38.878230: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-20 18:16:38.878239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "#!pip install keras_vggface\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8618f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender</th>\n",
       "      <th>is_training</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34.207396</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>img_0.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.453720</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>img_1.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34.967561</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_2.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22.044766</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_3.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>37.758789</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_4.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        bmi  gender  is_training       name\n",
       "0           0  34.207396    Male            1  img_0.bmp\n",
       "1           1  26.453720    Male            1  img_1.bmp\n",
       "2           2  34.967561  Female            1  img_2.bmp\n",
       "3           3  22.044766  Female            1  img_3.bmp\n",
       "4           4  37.758789  Female            1  img_4.bmp"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BMI dataset\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e62f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4206\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b4c1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3368\n",
      "838\n"
     ]
    }
   ],
   "source": [
    "print(len(data[data['is_training']==1]))\n",
    "print(len(data[data['is_training']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25578a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4206 entries, 0 to 4205\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   4206 non-null   int64  \n",
      " 1   bmi          4206 non-null   float64\n",
      " 2   gender       4206 non-null   object \n",
      " 3   is_training  4206 non-null   int64  \n",
      " 4   name         4206 non-null   object \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 164.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f5d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4a08150",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list=['img_4.bmp',\n",
    " 'img_5.bmp',\n",
    " 'img_40.bmp',\n",
    " 'img_86.bmp',\n",
    " 'img_93.bmp',\n",
    " 'img_112.bmp',\n",
    " 'img_113.bmp',\n",
    " 'img_238.bmp',\n",
    " 'img_239.bmp',\n",
    " 'img_300.bmp',\n",
    " 'img_301.bmp',\n",
    " 'img_309.bmp',\n",
    " 'img_436.bmp',\n",
    " 'img_437.bmp',\n",
    " 'img_530.bmp',\n",
    " 'img_531.bmp',\n",
    " 'img_579.bmp',\n",
    " 'img_617.bmp',\n",
    " 'img_670.bmp',\n",
    " 'img_671.bmp',\n",
    " 'img_734.bmp',\n",
    " 'img_735.bmp',\n",
    " 'img_742.bmp',\n",
    " 'img_820.bmp',\n",
    " 'img_824.bmp',\n",
    " 'img_860.bmp',\n",
    " 'img_861.bmp',\n",
    " 'img_1036.bmp',\n",
    " 'img_1037.bmp',\n",
    " 'img_1070.bmp',\n",
    " 'img_1099.bmp',\n",
    " 'img_1121.bmp',\n",
    " 'img_1127.bmp',\n",
    " 'img_1164.bmp',\n",
    " 'img_1172.bmp',\n",
    " 'img_1173.bmp',\n",
    " 'img_1300.bmp',\n",
    " 'img_1301.bmp',\n",
    " 'img_1324.bmp',\n",
    " 'img_1325.bmp',\n",
    " 'img_1326.bmp',\n",
    " 'img_1327.bmp',\n",
    " 'img_1472.bmp',\n",
    " 'img_1473.bmp',\n",
    " 'img_1524.bmp',\n",
    " 'img_1525.bmp',\n",
    " 'img_1612.bmp',\n",
    " 'img_1613.bmp',\n",
    " 'img_1618.bmp',\n",
    " 'img_1619.bmp',\n",
    " 'img_1704.bmp',\n",
    " 'img_1718.bmp',\n",
    " 'img_1719.bmp',\n",
    " 'img_1720.bmp',\n",
    " 'img_1721.bmp',\n",
    " 'img_1822.bmp',\n",
    " 'img_1823.bmp',\n",
    " 'img_1830.bmp',\n",
    " 'img_1846.bmp',\n",
    " 'img_1847.bmp',\n",
    " 'img_1848.bmp',\n",
    " 'img_1849.bmp',\n",
    " 'img_1862.bmp',\n",
    " 'img_1863.bmp',\n",
    " 'img_1886.bmp',\n",
    " 'img_1887.bmp',\n",
    " 'img_1954.bmp',\n",
    " 'img_1955.bmp',\n",
    " 'img_1972.bmp',\n",
    " 'img_1973.bmp',\n",
    " 'img_2072.bmp',\n",
    " 'img_2073.bmp',\n",
    " 'img_2080.bmp',\n",
    " 'img_2081.bmp',\n",
    " 'img_2100.bmp',\n",
    " 'img_2101.bmp',\n",
    " 'img_2130.bmp',\n",
    " 'img_2214.bmp',\n",
    " 'img_2215.bmp',\n",
    " 'img_2238.bmp',\n",
    " 'img_2239.bmp',\n",
    " 'img_2242.bmp',\n",
    " 'img_2243.bmp',\n",
    " 'img_2244.bmp',\n",
    " 'img_2245.bmp',\n",
    " 'img_2250.bmp',\n",
    " 'img_2251.bmp',\n",
    " 'img_2284.bmp',\n",
    " 'img_2292.bmp',\n",
    " 'img_2293.bmp',\n",
    " 'img_2294.bmp',\n",
    " 'img_2295.bmp',\n",
    " 'img_2322.bmp',\n",
    " 'img_2323.bmp',\n",
    " 'img_2327.bmp',\n",
    " 'img_2468.bmp',\n",
    " 'img_2469.bmp',\n",
    " 'img_2516.bmp',\n",
    " 'img_2531.bmp',\n",
    " 'img_2532.bmp',\n",
    " 'img_2566.bmp',\n",
    " 'img_2567.bmp',\n",
    " 'img_2586.bmp',\n",
    " 'img_2587.bmp',\n",
    " 'img_2652.bmp',\n",
    " 'img_2653.bmp',\n",
    " 'img_2666.bmp',\n",
    " 'img_2667.bmp',\n",
    " 'img_2712.bmp',\n",
    " 'img_2714.bmp',\n",
    " 'img_2715.bmp',\n",
    " 'img_2722.bmp',\n",
    " 'img_2730.bmp',\n",
    " 'img_2731.bmp',\n",
    " 'img_2738.bmp',\n",
    " 'img_2739.bmp',\n",
    " 'img_2750.bmp',\n",
    " 'img_2751.bmp',\n",
    " 'img_2785.bmp',\n",
    " 'img_2842.bmp',\n",
    " 'img_2843.bmp',\n",
    " 'img_2912.bmp',\n",
    " 'img_2913.bmp',\n",
    " 'img_2954.bmp',\n",
    " 'img_2955.bmp',\n",
    " 'img_2982.bmp',\n",
    " 'img_2983.bmp',\n",
    " 'img_2986.bmp',\n",
    " 'img_2987.bmp',\n",
    " 'img_3030.bmp',\n",
    " 'img_3031.bmp',\n",
    " 'img_3039.bmp',\n",
    " 'img_3070.bmp',\n",
    " 'img_3071.bmp',\n",
    " 'img_3084.bmp',\n",
    " 'img_3085.bmp',\n",
    " 'img_3103.bmp',\n",
    " 'img_3140.bmp',\n",
    " 'img_3141.bmp',\n",
    " 'img_3146.bmp',\n",
    " 'img_3152.bmp',\n",
    " 'img_3153.bmp',\n",
    " 'img_3188.bmp',\n",
    " 'img_3189.bmp',\n",
    " 'img_3268.bmp',\n",
    " 'img_3269.bmp',\n",
    " 'img_3284.bmp',\n",
    " 'img_3285.bmp',\n",
    " 'img_3298.bmp',\n",
    " 'img_3299.bmp',\n",
    " 'img_3320.bmp',\n",
    " 'img_3321.bmp',\n",
    " 'img_3336.bmp',\n",
    " 'img_3337.bmp',\n",
    " 'img_3340.bmp',\n",
    " 'img_3341.bmp',\n",
    " 'img_3366.bmp',\n",
    " 'img_3367.bmp',\n",
    " 'img_3368.bmp',\n",
    " 'img_3376.bmp',\n",
    " 'img_3377.bmp',\n",
    " 'img_3387.bmp',\n",
    " 'img_3394.bmp',\n",
    " 'img_3404.bmp',\n",
    " 'img_3405.bmp',\n",
    " 'img_3408.bmp',\n",
    " 'img_3409.bmp',\n",
    " 'img_3424.bmp',\n",
    " 'img_3425.bmp',\n",
    " 'img_3430.bmp',\n",
    " 'img_3431.bmp',\n",
    " 'img_3498.bmp',\n",
    " 'img_3499.bmp',\n",
    " 'img_3503.bmp',\n",
    " 'img_3504.bmp',\n",
    " 'img_3505.bmp',\n",
    " 'img_3530.bmp',\n",
    " 'img_3531.bmp',\n",
    " 'img_3570.bmp',\n",
    " 'img_3571.bmp',\n",
    " 'img_3590.bmp',\n",
    " 'img_3591.bmp',\n",
    " 'img_3630.bmp',\n",
    " 'img_3631.bmp',\n",
    " 'img_3656.bmp',\n",
    " 'img_3657.bmp',\n",
    " 'img_3660.bmp',\n",
    " 'img_3680.bmp',\n",
    " 'img_3681.bmp',\n",
    " 'img_3694.bmp',\n",
    " 'img_3695.bmp',\n",
    " 'img_3726.bmp',\n",
    " 'img_3727.bmp',\n",
    " 'img_3731.bmp',\n",
    " 'img_3764.bmp',\n",
    " 'img_3765.bmp',\n",
    " 'img_3790.bmp',\n",
    " 'img_3792.bmp',\n",
    " 'img_3793.bmp',\n",
    " 'img_3794.bmp',\n",
    " 'img_3795.bmp',\n",
    " 'img_3802.bmp',\n",
    " 'img_3803.bmp',\n",
    " 'img_3812.bmp',\n",
    " 'img_3813.bmp',\n",
    " 'img_3816.bmp',\n",
    " 'img_3826.bmp',\n",
    " 'img_3840.bmp',\n",
    " 'img_3841.bmp',\n",
    " 'img_3851.bmp',\n",
    " 'img_3854.bmp',\n",
    " 'img_3855.bmp',\n",
    " 'img_3878.bmp',\n",
    " 'img_3879.bmp',\n",
    " 'img_3880.bmp',\n",
    " 'img_3881.bmp',\n",
    " 'img_3900.bmp',\n",
    " 'img_3906.bmp',\n",
    " 'img_3907.bmp',\n",
    " 'img_3921.bmp',\n",
    " 'img_3922.bmp',\n",
    " 'img_3923.bmp',\n",
    " 'img_3931.bmp',\n",
    " 'img_3958.bmp',\n",
    " 'img_3966.bmp',\n",
    " 'img_3967.bmp',\n",
    " 'img_3970.bmp',\n",
    " 'img_3971.bmp',\n",
    " 'img_3973.bmp',\n",
    " 'img_3990.bmp',\n",
    " 'img_3991.bmp',\n",
    " 'img_3994.bmp',\n",
    " 'img_3995.bmp',\n",
    " 'img_4018.bmp',\n",
    " 'img_4019.bmp',\n",
    " 'img_4104.bmp',\n",
    " 'img_4105.bmp',\n",
    " 'img_4146.bmp',\n",
    " 'img_4147.bmp',\n",
    " 'img_4168.bmp',\n",
    " 'img_4174.bmp',\n",
    " 'img_4175.bmp',\n",
    " 'img_4182.bmp',\n",
    " 'img_4183.bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdb80cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data[~data['name'].isin(missing_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b74a009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3962"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_filtered\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cd8211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210\n",
      "752\n"
     ]
    }
   ],
   "source": [
    "print(len(data[data['is_training']==1]))\n",
    "print(len(data[data['is_training']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a7218f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data[\"is_training\"] == 1]\n",
    "test_data = data[data[\"is_training\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebe334da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = train_data[\"name\"].tolist()\n",
    "train_labels = train_data[\"bmi\"].tolist()\n",
    "\n",
    "val_paths = test_data[\"name\"].tolist()\n",
    "val_labels = test_data[\"bmi\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46916160-8f64-458b-a75f-709e8a22270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210\n",
      "752\n"
     ]
    }
   ],
   "source": [
    "print(len(train_paths))\n",
    "print(len(val_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd5eb60c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210\n",
      "752\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679debd3",
   "metadata": {},
   "source": [
    "#### Adding Custom Layers: The code adds custom layers on top of the VGG16 model. It adds a global average pooling layer to reduce the spatial dimensions, followed by a fully connected (dense) layer with ReLU activation function, and an output layer with a single neuron for BMI prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7ff9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras_applications\n",
    "#!pip install keras-vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a5a89ea-ffb8-47bc-a22c-1ef1eb2a31c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 18:16:42.217606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 18:16:42.229167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 18:16:42.230828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfbfb02c-7233-4171-827e-7a7933a1da33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 18:16:42.243911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.mixed_precision as mixed_precision\n",
    "\n",
    "# Enable GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Enable mixed precision training\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cab9e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 18:16:42.271256: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 18:16:42.271700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 18:16:42.273619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 18:16:42.275264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 18:16:43.063867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 18:16:43.065908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 18:16:43.067573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 18:16:43.069142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11749 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer with 128 neurons and L2 regularization\n",
    "x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# Add a fully connected layer with 128 neurons and L2 regularization\n",
    "x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# Add a fully connected layer with 128 neurons and L2 regularization\n",
    "x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# Add a fully connected layer with 128 neurons and L2 regularization\n",
    "x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# Add an output layer with 1 neuron for BMI prediction\n",
    "predictions = Dense(1)(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Unfreeze the last 5 layers of the pre-trained VGG16 model and apply L2 regularization\n",
    "for layer in model.layers[-5:]:\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        # Apply L2 regularization to convolutional layers\n",
    "        layer.kernel_regularizer = regularizers.l2(0.01)\n",
    "    if isinstance(layer, tf.keras.layers.Dense):\n",
    "        # Apply L2 regularization to dense layers\n",
    "        layer.kernel_regularizer = regularizers.l2(0.01)\n",
    "    layer.trainable = True\n",
    "for layer in model.layers[:15]:\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        # Apply L2 regularization to convolutional layers\n",
    "        layer.kernel_regularizer = regularizers.l2(0.01)\n",
    "    if isinstance(layer, tf.keras.layers.Dense):\n",
    "        # Apply L2 regularization to dense layers\n",
    "        layer.kernel_regularizer = regularizers.l2(0.01)\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with RMSprop optimizer and mean absolute error loss\n",
    "model.compile(optimizer=\"RMSprop\", loss=\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d7cc837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3210 validated image filenames.\n",
      "Found 752 validated image filenames.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 18:16:46.270830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n",
      "2023-05-20 18:16:49.456607: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x559de3a50d20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-20 18:16:49.456669: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-05-20 18:16:49.465166: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-20 18:16:49.465470: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-20 18:16:49.673237: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 48s 208ms/step - loss: 52.0342 - val_loss: 10.7847\n",
      "Epoch 2/30\n",
      "201/201 [==============================] - 40s 201ms/step - loss: 12.0872 - val_loss: 20.5770\n",
      "Epoch 3/30\n",
      "201/201 [==============================] - 40s 200ms/step - loss: 10.5155 - val_loss: 12.7034\n",
      "Epoch 4/30\n",
      "201/201 [==============================] - 41s 202ms/step - loss: 9.9762 - val_loss: 11.6333\n",
      "Epoch 5/30\n",
      "201/201 [==============================] - 41s 202ms/step - loss: 9.3538 - val_loss: 13.6250\n",
      "Epoch 6/30\n",
      "201/201 [==============================] - 40s 200ms/step - loss: 9.0410 - val_loss: 7.7955\n",
      "Epoch 7/30\n",
      "201/201 [==============================] - 41s 203ms/step - loss: 8.5302 - val_loss: 11.5785\n",
      "Epoch 8/30\n",
      "201/201 [==============================] - 41s 203ms/step - loss: 8.3333 - val_loss: 11.6225\n",
      "Epoch 9/30\n",
      "201/201 [==============================] - 40s 199ms/step - loss: 7.9170 - val_loss: 8.7065\n",
      "Epoch 10/30\n",
      "201/201 [==============================] - 40s 201ms/step - loss: 7.6099 - val_loss: 8.5349\n",
      "Epoch 11/30\n",
      "201/201 [==============================] - 40s 199ms/step - loss: 7.3509 - val_loss: 7.8741\n",
      "CPU times: user 8min 17s, sys: 12.8 s, total: 8min 29s\n",
      "Wall time: 7min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the image data generator with data augmentation\n",
    "datagen = image.ImageDataGenerator(rescale=1.0 / 255.0,  # Scale pixel values to [0, 1]\n",
    "                                   rotation_range=20,  # Randomly rotate images by 20 degrees\n",
    "                                   width_shift_range=0.2,  # Randomly shift images horizontally by 20% of the width\n",
    "                                   height_shift_range=0.2,  # Randomly shift images vertically by 20% of the height\n",
    "                                   shear_range=0.2,  # Apply random shear transformations\n",
    "                                   zoom_range=0.2,  # Apply random zoom transformations\n",
    "                                   horizontal_flip=True)  # Randomly flip images horizontally\n",
    "\n",
    "# Create training and validation data generators\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({\"path\": train_paths, \"BMI\": train_labels}),\n",
    "    x_col=\"path\",\n",
    "    y_col=\"BMI\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({\"path\": val_paths, \"BMI\": val_labels}),\n",
    "    x_col=\"path\",\n",
    "    y_col=\"BMI\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=30, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de41619-8d3d-4614-9aeb-d8da3cc60d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"bmi_mode_2005_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16257217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 8s 164ms/step\n",
      "CPU times: user 9.8 s, sys: 208 ms, total: 10 s\n",
      "Wall time: 8.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate predictions for the validation set\n",
    "val_predictions = model.predict(val_generator)\n",
    "val_predictions = val_predictions.flatten()\n",
    "\n",
    "# Create a dataframe for actual and predicted BMI values\n",
    "val_results = pd.DataFrame({'Actual BMI': val_labels, 'Predicted BMI': val_predictions})\n",
    "\n",
    "# Add the image file names column\n",
    "val_results['Image File'] = val_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4f34724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual BMI</th>\n",
       "      <th>Predicted BMI</th>\n",
       "      <th>Image File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.698495</td>\n",
       "      <td>29.906250</td>\n",
       "      <td>img_3369.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.845918</td>\n",
       "      <td>36.062500</td>\n",
       "      <td>img_3370.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.389796</td>\n",
       "      <td>28.765625</td>\n",
       "      <td>img_3371.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.258679</td>\n",
       "      <td>32.406250</td>\n",
       "      <td>img_3372.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.891291</td>\n",
       "      <td>28.812500</td>\n",
       "      <td>img_3373.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.743467</td>\n",
       "      <td>28.593750</td>\n",
       "      <td>img_3374.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.370844</td>\n",
       "      <td>29.406250</td>\n",
       "      <td>img_3375.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60.096828</td>\n",
       "      <td>28.046875</td>\n",
       "      <td>img_3378.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34.256669</td>\n",
       "      <td>28.359375</td>\n",
       "      <td>img_3379.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28.884838</td>\n",
       "      <td>35.968750</td>\n",
       "      <td>img_3380.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.460455</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>img_3381.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.631772</td>\n",
       "      <td>29.453125</td>\n",
       "      <td>img_3382.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26.144628</td>\n",
       "      <td>27.828125</td>\n",
       "      <td>img_3383.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29.798443</td>\n",
       "      <td>28.187500</td>\n",
       "      <td>img_3384.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.021194</td>\n",
       "      <td>31.359375</td>\n",
       "      <td>img_3385.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>41.191406</td>\n",
       "      <td>32.281250</td>\n",
       "      <td>img_3386.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38.338816</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>img_3388.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33.470395</td>\n",
       "      <td>26.765625</td>\n",
       "      <td>img_3389.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41.191406</td>\n",
       "      <td>29.453125</td>\n",
       "      <td>img_3390.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29.177246</td>\n",
       "      <td>36.125000</td>\n",
       "      <td>img_3391.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual BMI  Predicted BMI    Image File\n",
       "0    29.698495      29.906250  img_3369.bmp\n",
       "1    30.845918      36.062500  img_3370.bmp\n",
       "2    24.389796      28.765625  img_3371.bmp\n",
       "3    36.258679      32.406250  img_3372.bmp\n",
       "4    27.891291      28.812500  img_3373.bmp\n",
       "5    36.743467      28.593750  img_3374.bmp\n",
       "6    23.370844      29.406250  img_3375.bmp\n",
       "7    60.096828      28.046875  img_3378.bmp\n",
       "8    34.256669      28.359375  img_3379.bmp\n",
       "9    28.884838      35.968750  img_3380.bmp\n",
       "10   23.460455      31.750000  img_3381.bmp\n",
       "11   31.631772      29.453125  img_3382.bmp\n",
       "12   26.144628      27.828125  img_3383.bmp\n",
       "13   29.798443      28.187500  img_3384.bmp\n",
       "14   24.021194      31.359375  img_3385.bmp\n",
       "15   41.191406      32.281250  img_3386.bmp\n",
       "16   38.338816      26.500000  img_3388.bmp\n",
       "17   33.470395      26.765625  img_3389.bmp\n",
       "18   41.191406      29.453125  img_3390.bmp\n",
       "19   29.177246      36.125000  img_3391.bmp"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16d9fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 8s 161ms/step\n",
      "Validation RMSE: 10.619774783004708\n",
      "Validation MAE: 7.79690765935625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calculate predictions for the validation set\n",
    "val_predictions = model.predict(val_generator)\n",
    "val_predictions = val_predictions.flatten()\n",
    "\n",
    "# Calculate RMSE\n",
    "val_rmse = np.sqrt(mean_squared_error(val_labels, val_predictions))\n",
    "\n",
    "# Calculate MAE\n",
    "val_mae = mean_absolute_error(val_labels, val_predictions)\n",
    "\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "print(\"Validation MAE:\", val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4578d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.46475818694426374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Convert actual BMI values to binary labels (0 or 1)\n",
    "actual_labels = pd.cut(val_results['Actual BMI'], bins=[0, 24.9, np.inf], labels=[0, 1])\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(actual_labels, val_results['Predicted BMI'])\n",
    "\n",
    "# Print AUC\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77782f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.3460724925824106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "# Calculate R2 score\n",
    "val_r2 = r2_score(val_results['Actual BMI'], val_results['Predicted BMI'])\n",
    "print(\"R2 Score:\",val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c9385a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame called 'df'\n",
    "# ...\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "val_results.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a066b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe52e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75ff76-997d-4c39-854f-1174339fc602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da2e49-583a-44e2-ab62-9798f696c886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af24ac6-0ae7-435e-91e8-9597573dee98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1600ec-12f2-48d3-ae0d-bcc4ed88f62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b02235-3a64-4304-bddc-0d27ea9b9835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e3feb-1e0b-46d2-a261-d28dc93dbee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c74a5f-acbb-4f32-bcdf-eec18f381b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4323f69-dd4b-4252-bba2-384159f13b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a720d-470a-4202-9e9d-9c24bbc9dbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562706b2-0cc8-48e8-9522-3f0cb07ee164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8d0bf-5386-41f0-b5c9-94520683db7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
