{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed3c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "#!pip install keras_vggface\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8618f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender</th>\n",
       "      <th>is_training</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34.207396</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>img_0.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.453720</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>img_1.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34.967561</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_2.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22.044766</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_3.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>37.758789</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_4.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        bmi  gender  is_training       name\n",
       "0           0  34.207396    Male            1  img_0.bmp\n",
       "1           1  26.453720    Male            1  img_1.bmp\n",
       "2           2  34.967561  Female            1  img_2.bmp\n",
       "3           3  22.044766  Female            1  img_3.bmp\n",
       "4           4  37.758789  Female            1  img_4.bmp"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BMI dataset\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38e62f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4206\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62b4c1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3368\n",
      "838\n"
     ]
    }
   ],
   "source": [
    "print(len(data[data['is_training']==1]))\n",
    "print(len(data[data['is_training']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25578a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4206 entries, 0 to 4205\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   4206 non-null   int64  \n",
      " 1   bmi          4206 non-null   float64\n",
      " 2   gender       4206 non-null   object \n",
      " 3   is_training  4206 non-null   int64  \n",
      " 4   name         4206 non-null   object \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 164.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "image_paths='C:/Users/kisho/Desktop/UChicago Academics/Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68f5d021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0  bmi        gender  is_training  name        \n",
       "0           34.207396  Male    1            img_0.bmp       1\n",
       "2793        28.662354  Female  1            img_2793.bmp    1\n",
       "2795        26.289704  Female  1            img_2795.bmp    1\n",
       "2796        33.792661  Male    1            img_2796.bmp    1\n",
       "2797        28.160551  Male    1            img_2797.bmp    1\n",
       "                                                           ..\n",
       "1407        46.511695  Female  1            img_1407.bmp    1\n",
       "1408        26.622856  Male    1            img_1408.bmp    1\n",
       "1409        24.900200  Male    1            img_1409.bmp    1\n",
       "1410        50.029844  Male    1            img_1410.bmp    1\n",
       "4205        34.618844  Male    0            img_4205.bmp    1\n",
       "Length: 4206, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4a08150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the image paths and labels\n",
    "image_paths = data[\"name\"].values\n",
    "\n",
    "valid_image_paths = []\n",
    "import os\n",
    "missing_images=0\n",
    "missing_list = []\n",
    "for image_path in image_paths:\n",
    "    if os.path.isfile(image_path):\n",
    "        valid_image_paths.append(image_path)\n",
    "    else:\n",
    "        missing_images+=1\n",
    "        missing_list.append(image_path)\n",
    "        #print(f\"Image file not found: {image_path}\")\n",
    "        \n",
    "print(missing_images)\n",
    "#print(missing_list)\n",
    "#image_paths = valid_image_paths\n",
    "#labels = data[\"bmi\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdb80cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data[~data['name'].isin(missing_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b74a009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3962"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_filtered\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cd8211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210\n",
      "752\n"
     ]
    }
   ],
   "source": [
    "print(len(data[data['is_training']==1]))\n",
    "print(len(data[data['is_training']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a7218f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data[\"is_training\"] == 1]\n",
    "test_data = data[data[\"is_training\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe334da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = train_data[\"name\"].tolist()\n",
    "train_labels = train_data[\"bmi\"].tolist()\n",
    "\n",
    "val_paths = test_data[\"name\"].tolist()\n",
    "val_labels = test_data[\"bmi\"].tolist()\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "#    train_paths, train_labels, test_size=0.2, random_state=42\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd5eb60c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210\n",
      "752\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679debd3",
   "metadata": {},
   "source": [
    "#### Adding Custom Layers: The code adds custom layers on top of the VGG16 model. It adds a global average pooling layer to reduce the spatial dimensions, followed by a fully connected (dense) layer with ReLU activation function, and an output layer with a single neuron for BMI prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9360177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras_applications\n",
    "#!pip install keras-vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cab9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer with more neurons\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "# Add a Dropout layer with a dropout rate of 0.5\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add a fully connected layer with more neurons\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "\n",
    "# Add a Dropout layer with a dropout rate of 0.5\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add a fully connected layer with more neurons\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "\n",
    "# Add a Dropout layer with a dropout rate of 0.5\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add an output layer with 1 neuron for BMI prediction\n",
    "predictions = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Unfreeze the last 3 layers of the pre-trained VGG16 model\n",
    "for layer in base_model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.compile(optimizer=\"Adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d7cc837",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3210 validated image filenames.\n",
      "Found 752 validated image filenames.\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 1038s 10s/step - loss: 3699351.7500 - val_loss: 172.3060\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 1003s 10s/step - loss: 120.1543 - val_loss: 91.4947\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 1018s 10s/step - loss: 116.4336 - val_loss: 131.5399\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 1006s 10s/step - loss: 105.0548 - val_loss: 90.0963\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 1004s 10s/step - loss: 100.5901 - val_loss: 96.7654\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 1002s 10s/step - loss: 99.4276 - val_loss: 107.3162\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 1003s 10s/step - loss: 94.0835 - val_loss: 110.0130\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 999s 10s/step - loss: 96.2725 - val_loss: 88.4789\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 1021s 10s/step - loss: 94.2180 - val_loss: 116.1408\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 999s 10s/step - loss: 94.5932 - val_loss: 101.7500\n",
      "CPU times: total: 14h 46min 38s\n",
      "Wall time: 2h 48min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# This is to use preprocessing techniques to the images to improve the performance\n",
    "# Define the image data generator with data augmentation\n",
    "datagen = image.ImageDataGenerator(rescale=1.0 / 255.0,  # Scale pixel values to [0, 1]\n",
    "                                   rotation_range=20,  # Randomly rotate images by 20 degrees\n",
    "                                   width_shift_range=0.2,  # Randomly shift images horizontally by 20% of the width\n",
    "                                   height_shift_range=0.2,  # Randomly shift images vertically by 20% of the height\n",
    "                                   shear_range=0.2,  # Apply random shear transformations\n",
    "                                   zoom_range=0.2,  # Apply random zoom transformations\n",
    "                                   horizontal_flip=True)  # Randomly flip images horizontally\n",
    "\n",
    "# Create training data generator with augmentation\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({\"path\": train_paths, \"BMI\": train_labels}),\n",
    "    x_col=\"path\",\n",
    "    y_col=\"BMI\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({\"path\": val_paths, \"BMI\": val_labels}),\n",
    "    x_col=\"path\",\n",
    "    y_col=\"BMI\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f999bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have trained a model and obtained the `model` object\n",
    "\n",
    "# Save the entire model\n",
    "model.save(\"20230518_Mid_mtcnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16257217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 42s 2s/step\n",
      "Validation Accuracy: 0.8404255319148937\n",
      "     Actual BMI  Predicted BMI    Image File Actual BMI Category  \\\n",
      "0     29.698495      28.206894  img_3369.bmp          Overweight   \n",
      "1     30.845918      28.010355  img_3370.bmp          Overweight   \n",
      "2     24.389796      28.489431  img_3371.bmp       Normal Weight   \n",
      "3     36.258679      29.410398  img_3372.bmp          Overweight   \n",
      "4     27.891291      27.815912  img_3373.bmp          Overweight   \n",
      "..          ...            ...           ...                 ...   \n",
      "747   34.078947      28.802694  img_4201.bmp          Overweight   \n",
      "748   34.564776      28.422501  img_4202.bmp          Overweight   \n",
      "749   27.432362      28.249756  img_4203.bmp          Overweight   \n",
      "750   40.492800      28.709631  img_4204.bmp          Overweight   \n",
      "751   34.618844      28.324493  img_4205.bmp          Overweight   \n",
      "\n",
      "    Predicted BMI Category  \n",
      "0               Overweight  \n",
      "1               Overweight  \n",
      "2               Overweight  \n",
      "3               Overweight  \n",
      "4               Overweight  \n",
      "..                     ...  \n",
      "747             Overweight  \n",
      "748             Overweight  \n",
      "749             Overweight  \n",
      "750             Overweight  \n",
      "751             Overweight  \n",
      "\n",
      "[752 rows x 5 columns]\n",
      "CPU times: total: 7min 6s\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate predictions for the validation set\n",
    "val_predictions = model.predict(val_generator)\n",
    "val_predictions = val_predictions.flatten()\n",
    "\n",
    "# Create a dataframe for actual and predicted BMI values\n",
    "val_results = pd.DataFrame({'Actual BMI': val_labels, 'Predicted BMI': val_predictions})\n",
    "\n",
    "# Add the image file names column\n",
    "val_results['Image File'] = val_paths\n",
    "\n",
    "# Define the BMI categories\n",
    "bmi_categories = [\"Underweight\", \"Normal Weight\", \"Overweight\"]\n",
    "\n",
    "# Convert actual BMI values to BMI categories\n",
    "val_results['Actual BMI Category'] = pd.cut(val_results['Actual BMI'], bins=[0, 18.5, 25, np.inf], labels=bmi_categories)\n",
    "\n",
    "# Convert predicted BMI values to BMI categories\n",
    "val_results['Predicted BMI Category'] = pd.cut(val_results['Predicted BMI'], bins=[0, 18.5, 25, np.inf], labels=bmi_categories)\n",
    "\n",
    "# Calculate accuracy\n",
    "val_accuracy = accuracy_score(val_results['Actual BMI Category'], val_results['Predicted BMI Category'])\n",
    "\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4f34724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16d9fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 41s 2s/step\n",
      "Validation RMSE: 10.595192118698359\n",
      "Validation MAE: 7.5933334202499445\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calculate predictions for the validation set\n",
    "val_predictions = model.predict(val_generator)\n",
    "val_predictions = val_predictions.flatten()\n",
    "\n",
    "# Calculate RMSE\n",
    "val_rmse = np.sqrt(mean_squared_error(val_labels, val_predictions))\n",
    "\n",
    "# Calculate MAE\n",
    "val_mae = mean_absolute_error(val_labels, val_predictions)\n",
    "\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "print(\"Validation MAE:\", val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4578d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.47596779440468445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Convert actual BMI values to binary labels (0 or 1)\n",
    "actual_labels = pd.cut(val_results['Actual BMI'], bins=[0, 24.9, np.inf], labels=[0, 1])\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(actual_labels, val_results['Predicted BMI'])\n",
    "\n",
    "# Print AUC\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77782f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.3198789670280511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "# Calculate R2 score\n",
    "val_r2 = r2_score(val_results['Actual BMI'], val_results['Predicted BMI'])\n",
    "print(\"R2 Score:\",val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c9385a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame called 'df'\n",
    "# ...\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "val_results.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a066b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a4b5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
